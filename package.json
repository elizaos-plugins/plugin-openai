{
  "name": "@elizaos/plugin-openai",
  "version": "1.0.1",
  "type": "module",
  "main": "dist/index.js",
  "module": "dist/index.js",
  "types": "dist/index.d.ts",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/elizaos-plugins/plugin-openai.git"
  },
  "exports": {
    "./package.json": "./package.json",
    ".": {
      "import": {
        "types": "./dist/index.d.ts",
        "default": "./dist/index.js"
      }
    }
  },
  "files": [
    "dist"
  ],
  "dependencies": {
    "@ai-sdk/openai": "^1.3.20",
    "@elizaos/core": "^1.0.0",
    "ai": "^4.3.16",
    "js-tiktoken": "^1.0.18",
    "tsup": "8.5.0",
    "undici": "^7.10.0"
  },
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "lint": "prettier --write ./src",
    "clean": "rm -rf dist .turbo node_modules .turbo-tsconfig.json tsconfig.tsbuildinfo",
    "format": "prettier --write ./src",
    "format:check": "prettier --check ./src",
    "test": "npx elizaos test"
  },
  "publishConfig": {
    "access": "public"
  },
  "agentConfig": {
    "pluginType": "elizaos:plugin:1.0.0",
    "pluginParameters": {
      "OPENAI_API_KEY": {
        "type": "string",
        "description": "API key for the service"
      },
      "OPENAI_BASE_URL": {
        "type": "string",
        "description": "Custom OpenAI API endpoint",
        "required": false,
        "default": "https://api.openai.com/v1"
      },
      "OPENAI_SMALL_MODEL": {
        "type": "string",
        "description": "Model ID for small/fast text tasks",
        "required": false,
        "default": "gpt-4o-mini"
      },
      "OPENAI_LARGE_MODEL": {
        "type": "string",
        "description": "Model ID for large/complex text tasks",
        "required": false,
        "default": "gpt-4o"
      },
      "OPENAI_EMBEDDING_MODEL": {
        "type": "string",
        "description": "Model ID used for generating text embeddings",
        "required": false,
        "default": "text-embedding-3-small"
      },
      "OPENAI_EMBEDDING_URL": {
        "type": "string",
        "description": "Custom endpoint for embedding requests",
        "required": false,
        "default": "value of OPENAI_BASE_URL if not set"
      },
      "OPENAI_EMBEDDING_DIMENSIONS": {
        "type": "number",
        "description": "Number of dimensions for embedding vectors",
        "required": false,
        "default": 1536
      },
      "OPENAI_IMAGE_DESCRIPTION_MODEL": {
        "type": "string",
        "description": "Model ID used for image description tasks",
        "required": false,
        "default": "gpt-4o-mini"
      },
      "OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS": {
        "type": "number",
        "description": "Maximum tokens allowed for image description responses",
        "required": false,
        "default": 8192
      },
      "SMALL_MODEL": {
        "type": "string",
        "description": "Generic fallback small model name if provider-specific variable is not set",
        "required": false,
        "default": "gpt-4o-mini"
      },
      "LARGE_MODEL": {
        "type": "string",
        "description": "Generic fallback large model name if provider-specific variable is not set",
        "required": false,
        "default": "gpt-4o"
      },
      "OPENAI_TTS_MODEL": {
        "type": "string",
        "description": "Model name to be used for text-to-speech requests",
        "required": false,
        "default": "gpt-4o-mini-tts"
      },
      "OPENAI_TTS_VOICE": {
        "type": "string",
        "description": "Voice preset to use with text-to-speech generation",
        "required": false,
        "default": "nova"
      },
      "OPENAI_TTS_INSTRUCTIONS": {
        "type": "string",
        "description": "Custom instructions or style prompts for text-to-speech output",
        "required": false
      }
    }
  },
  "gitHead": "646c632924826e2b75c2304a75ee56959fe4a460",
  "devDependencies": {
    "prettier": "3.5.3",
    "typescript": "^5.8.2"
  }
}
